{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Overview\n",
    "\n",
    "Using AIS vessel observation data to find interesting patters in recreational vessel traffic. \n",
    "\n",
    "* Create and display observation data as tracks\n",
    "* Determine areas of interest using dwell detection\n",
    "* Find common routes between interesting areas\n",
    "* Detect potential anomalies in vessel traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoanalytics\n",
    "import geoanalytics.sql.functions as ST\n",
    "import geoanalytics.tracks.functions as TRK\n",
    "import pyspark.sql.functions as F\n",
    "from geoanalytics.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from esrimap import EsriJSMap, Renderers, Labels, Popups\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Add display method to DataFrame for additional convenience\n",
    "DataFrame.display_layer = EsriJSMap.display_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up plotting extent and style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "san_pedro_bay = (-118.303734,33.701202,-118.178078,33.779397)\n",
    "coast_of_la = (-119.2388,33.2165,-117.2804,34.1125)\n",
    "\n",
    "bay_extent = san_pedro_bay\n",
    "demo_extent = coast_of_la\n",
    "output_path = None # \"C:/dev/demo/uc2025/sandbox/la_coast_demo\"\n",
    "\n",
    "demo_figsize=(14, 14)\n",
    "demo_basemap=\"light\"\n",
    "\n",
    "demo_style = dict(basemap=demo_basemap, extent=demo_extent, figsize=demo_figsize, quantize=True, sr=4326)\n",
    "bay_style = dict(basemap=demo_basemap, extent=bay_extent, figsize=demo_figsize, sr=4326)\n",
    "\n",
    "area_style = dict(alpha=.3, cmap_values=\"type\", edgecolor=\"black\")\n",
    "line_style = dict(edgecolor=\"blue\")\n",
    "\n",
    "# Setup plotting and utilities\n",
    "\n",
    "# Disable x-ticks and y-ticks using rcParams\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['xtick.labelbottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "\n",
    "\n",
    "# Show demo extent\n",
    "spark.sql(\"select st_point(0, 0, 4326)\").st.plot(**demo_style)\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AIS data and filter to demo extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset from parquet, filter to June and July, and create point geometry column in WGS84\n",
    "ais = spark.read.format(\"parquet\").load(\"C:/dev/demo/commondata/ais_parquet\")\\\n",
    "  .where(\"month in (6,7)\")\\\n",
    "  .withColumn(\"location\", ST.point(\"lon\", \"lat\", 4326))\n",
    "\n",
    "# Assign vessel group based on vessel type in data\n",
    "ais = ais.withColumn(\"vesselgroup\", F.when(F.expr(\"vesseltype == 30\"), \"fishing\")\n",
    "                              .when(F.expr(\"vesseltype == 35\"), \"military\")\n",
    "                              .when(F.expr(\"vesseltype in (36, 37)\"), \"recreational\")\n",
    "                              .when(F.expr(\"vesseltype in (21, 22, 31, 32, 52)\"), \"tug\")\n",
    "                              .when(F.expr(\"vesseltype == 50\"), \"pilot\")\n",
    "                              .when(F.expr(\"vesseltype == 51\"), \"S&R\")\n",
    "                              .when(F.expr(\"vesseltype between 60 and 69\"), \"passenger\")\n",
    "                              .when(F.expr(\"vesseltype between 70 and 79\"), \"cargo\")\n",
    "                              .when(F.expr(\"vesseltype between 80 and 89\"), \"tanker\"))\\\n",
    "   .select(\"mmsi\", \"basedatetime\", \"location\", \"vesselgroup\")\n",
    "\n",
    "\n",
    "# Filter to observations within our demo extent\n",
    "ais = ais.where(ST.bbox_intersects(\"location\", *demo_extent))\n",
    "\n",
    "# Project to CA state plane for processing\n",
    "ais = ais.withColumn(\"location\", ST.transform(\"location\", 2230))\\\n",
    "\n",
    "print(\"Observation Count: \" + str(ais.persist().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display breakdown of vessel types in demo extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais.groupBy(\"vesselgroup\").agg(\n",
    "      F.countDistinct(\"mmsi\").alias(\"unique_vessels\"), \n",
    "      F.count(\"*\").alias(\"observation_count\"))\\\n",
    "   .orderBy(\"unique_vessels\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tracks for recreational vessels\n",
    "\n",
    "* Split tracks based on one week interval\n",
    "* Discard segments that span more than 3000 meters (e.g., distance between consecutive observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "user_track_fields = [\"mmsi\"]\n",
    "track_fields = [*user_track_fields, \"track_index\"]\n",
    "\n",
    "ais_tracks = ais.where(\"vesselgroup = 'recreational'\")\\\n",
    "  .groupBy(*user_track_fields).agg(TRK.aggr_create_track(\"location\", \"BaseDateTime\").alias(\"track\")) \\\n",
    "  .withColumn(\"track\", F.explode(TRK.split_by_duration(\"track\", (7, \"days\")))) \\\n",
    "  .withColumn(\"track\", F.explode(TRK.split_by_distance_gap(\"track\", (3000, \"meters\")))) \\\n",
    "  .withColumn(\"track_index\", F.row_number().over(Window.partitionBy(*user_track_fields).orderBy(TRK.start_timestamp(\"track\")))) \\\n",
    "  .persist()\n",
    "\n",
    "\n",
    "print(\"Track Count: \" + str(ais_tracks.count()))\n",
    "\n",
    "ais_tracks.st.plot(**demo_style, edgecolor=\"#FF0000A0\", linewidth=.1)\n",
    "\n",
    "if output_path:\n",
    "    ais_tracks.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find dwell events\n",
    "\n",
    "* Distance Threshold: **150 meters**\n",
    "* Minimum dwell duration: **1 hour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_events = ais_tracks\\\n",
    "  .withColumn(\"dwell\", F.explode(TRK.find_dwells(\"track\", (150, \"meters\"), (1, \"hour\"))))\\\n",
    "  .selectExpr(\n",
    "    *track_fields,\n",
    "    \"ST_Centroid(dwell) as dwell_centroid\",\n",
    "    \"TRK_StartTimestamp(dwell) as dwell_start\"\n",
    "  )\\\n",
    "  .coalesce(10)\\\n",
    "  .persist()\n",
    "\n",
    "dwell_events.st.plot(**bay_style)\n",
    "\n",
    "if output_path:\n",
    "    dwell_events.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/dwells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate areas of interest by finding groups of proximal dwell locations\n",
    "\n",
    "1. Group dwells such that events within 300 meters of each other are in the same group\n",
    "2. Create convex hull around all dwells in a group\n",
    "3. Filter out groups with less than 15 dwell events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_clusters = GroupByProximity()\\\n",
    "  .setSpatialRelationship(\"NearPlanar\", 300, \"meters\")\\\n",
    "  .run(dwell_events)\\\n",
    "  .groupBy(\"group_id\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    ST.aggr_convex_hull(\"dwell_centroid\").alias(\"dwell_area\")\n",
    "  )\\\n",
    "  .withColumn(\"dwell_area\", ST.buffer(\"dwell_area\", (100, \"meters\")))\\\n",
    "  .where(\"count > 15\")\\\n",
    "  .coalesce(10)\\\n",
    "  .persist()\n",
    "\n",
    "\n",
    "map = EsriJSMap(basemap=\"oceans\")\n",
    "map.add_layer(dwell_clusters, color=[255, 0, 0, .5], popup=[\"count\"])\n",
    "map.add_layer(dwell_events, color=\"black\", size=\"5px\")\n",
    "map.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javascript Map Source: https://github.com/climbage/uc/tree/main/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign useful labels to areas\n",
    "\n",
    "* Load TIGER water body data from Census\n",
    "* Join with dwell areas and select label from water body with largest intersecting area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all water bodies except oceans\n",
    "awater = spark.read.format(\"shapefile\").load(r\"C:\\dev\\demo\\uc2025\\sandbox\\tiger\\areawater\")\\\n",
    "  .where(ST.bbox_intersects(\"geometry\", *demo_extent))\\\n",
    "  .where(\"fullname not like '%Ocean%'\")\\\n",
    "  .withColumnRenamed(\"geometry\", \"water_polygon\")\n",
    "\n",
    "areas = dwell_clusters.join(awater, ST.intersects(\"dwell_area\", \"water_polygon\"), \"left\")\\\n",
    "  .groupBy(\"group_id\").agg(\n",
    "      F.max_by(\"FULLNAME\", ST.area(ST.intersection(\"water_polygon\", \"dwell_area\"))).alias(\"label\"),\n",
    "      F.first(\"dwell_area\").alias(\"dwell_area\")\n",
    "  )\\\n",
    "  .withColumn(\"label\", F.when(F.expr(\"label == '' or label is null\"), F.expr(\"concat('Unnamed ', monotonically_increasing_id())\")).otherwise(F.expr(\"label\")))\\\n",
    "  .persist()\n",
    "\n",
    "areas.display_layer(basemap=\"gray-vector\", label=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_path:\n",
    "    areas.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/areas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find every instance of a track traveling through a dwell area\n",
    "\n",
    "1. Join tracks with dwell areas\n",
    "2. Find all enter/exit events\n",
    "3. Discard events less than 10 minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapsing dwells reduces the number of points in the track and improves geofence performance\n",
    "geofence_tracks = ais_tracks.withColumn(\"track\", TRK.collapse_dwells(\"track\", (100, \"meters\"), (30, \"minutes\")))\n",
    "\n",
    "geofence_events = geofence_tracks.join(areas, ST.intersects(\"track\", \"dwell_area\"))\\\n",
    "    .withColumn(\"event\", F.explode(TRK.entry_exit_points(\"track\", \"dwell_area\")))\\\n",
    "    .where(\"cast(event.exit.time as long) - cast(event.entry.time as long) > 10 * 60\")\\\n",
    "    .select(\n",
    "        *track_fields, \n",
    "        F.col(\"label\").alias(\"event_label\"),\n",
    "        F.inline(F.array(\n",
    "            F.struct(F.col(\"event.entry.time\").alias(\"event_time\"), \n",
    "                     F.col(\"event.entry.point\").alias(\"event_location\"),\n",
    "                     F.when(F.col(\"event.entry.track_endpoint\"), \"Begin\").otherwise(\"Enter\").alias(\"event_type\")),\n",
    "            F.struct(F.col(\"event.exit.time\").alias(\"event_time\"), \n",
    "                     F.col(\"event.exit.point\").alias(\"event_location\"),\n",
    "                     F.when(F.col(\"event.exit.track_endpoint\"), \"End\").otherwise(\"Exit\").alias(\"event_type\"))\n",
    "        ))\n",
    "    )\n",
    "\n",
    "geofence_events = geofence_events.persist()\n",
    "print(\"Event Count: \" + str(geofence_events.count()))\n",
    "\n",
    "geofence_events.withColumn(\"event_time\", F.col(\"event_time\").cast(\"string\"))\\\n",
    "  .display_layer(popup=[\"mmsi\", \"track_index\", \"event_type\", \"event_label\", \"event_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_path:\n",
    "    geofence_events.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/geofence_events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"trips\" between areas of interest\n",
    "\n",
    "* Each trip starts when a vessel exits an area of interest and ends when it enters another area of interest.\n",
    "* Trips that exit and enter the same area are discarded\n",
    "* Short trips (<500 meters) are also ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `lead` window function to include the next geofence event in each row. Each trip goes from the\n",
    "# event in the row to the newly added next event.\n",
    "trips = geofence_events\\\n",
    "  .withColumn(\"event\", F.struct(\"event_location\", \"event_label\", \"event_time\"))\\\n",
    "  .select(*track_fields, \"event\", F.lead(\"event\").over(Window.partitionBy(\"mmsi\", \"track_index\").orderBy(\"event_time\")).alias(\"next_event\"))\n",
    "\n",
    "# Rejoin with track and compute the trip start and end offsets in seconds\n",
    "trips = trips.join(ais_tracks, on=track_fields)\\\n",
    "             .withColumn(\"track_start_seconds\", F.unix_timestamp(TRK.start_timestamp(\"track\")))\\\n",
    "             .withColumn(\"event_offset\", F.unix_timestamp(\"event.event_time\") - F.col(\"track_start_seconds\"))\\\n",
    "             .withColumn(\"next_event_offset\", F.unix_timestamp(\"next_event.event_time\") - F.col(\"track_start_seconds\"))\n",
    "\n",
    "# Use offsets to cut each track into subtracks\n",
    "trips = trips.withColumn(\"subtrack\", TRK.between(\"track\", (\"event_offset\", \"seconds\"), (\"next_event_offset\", \"seconds\")))\\\n",
    "             .withColumn(\"subtrack_length\", TRK.length(\"subtrack\"))\n",
    "\n",
    "trips = trips.selectExpr(*track_fields, \n",
    "                         \"event.event_label as orig\", \n",
    "                         \"next_event.event_label as dest\", \n",
    "                         \"subtrack as track\", \n",
    "                         \"subtrack_length as length\")\n",
    "\n",
    "# Remove trips that just return to the same area or are less than 500 meters\n",
    "trips = trips.where(\"orig != dest and length > 500\")\n",
    "\n",
    "# Create canonical ID for the bidirectional segment between two locations\n",
    "trips = trips.withColumn(\"route_id\", F.array_join(F.array_sort(F.array(\"orig\", \"dest\")), \" - \"))\n",
    "\n",
    "print(\"Trip Count: \" + str(trips.persist().count()))\n",
    "\n",
    "trips.where(\"mmsi = '338054481'\").show(truncate=50)\n",
    "\n",
    "if output_path:\n",
    "    trips.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize trips in ArcGIS Pro\n",
    "\n",
    "* Use new geoparquet layer type\n",
    "* Identify patterns in trip length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group trips together based on length\n",
    "\n",
    "* Trips whose distances are within 0.1% of each other are grouped together\n",
    "* Use route_id which ignores directionality (e.g., orig -> dest = dest -> orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_groups = GroupByProximity()\\\n",
    "  .setSpatialRelationship(\"NearPlanar\", 500, \"meters\")\\\n",
    "  .setAttributeRelationship(f\"\"\"\n",
    "      a.route_id = b.route_id\n",
    "      and abs(a.length - b.length) < a.length * .001\n",
    "   \"\"\")\\\n",
    "  .run(trips)\\\n",
    "  .withColumnRenamed(\"group_id\", \"trip_group\")\n",
    "\n",
    "# Count the number of trips per group\n",
    "trip_groups = trip_groups.withColumn(\"group_size\", F.count(\"*\").over(Window.partitionBy(\"trip_group\")))\\\n",
    "  .persist()\n",
    "\n",
    "if output_path:\n",
    "    trip_groups.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/trip_groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify common routes by averaging similar trips\n",
    "\n",
    "1. For each route, choose a representative trip track\n",
    "2. Iterate vertices in representative track and average the closest points on all other tracks in route\n",
    "3. Create line from average points as an approximate of the route line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_routes = trip_groups\\\n",
    "           .withColumn(\"max_for_route\", F.max_by(\"trip_group\", \"group_size\").over(Window.partitionBy(\"route_id\")))\\\n",
    "           .where(\"trip_group = max_for_route and group_size > 2\")\\\n",
    "           .drop(\"max_for_route\")\\\n",
    "           .groupBy(\"route_id\").agg(\n",
    "               F.min_by(\"track\", \"length\").alias(\"rep_track\"),\n",
    "               F.collect_list(\"track\").alias(\"all_tracks\"),\n",
    "               F.first(\"group_size\").alias(\"group_size\")\n",
    "           )\\\n",
    "           .withColumn(\"mean_trip_line\", F.expr(\"st_linestring(transform(st_points(rep_track), pt -> st_centroid(st_multipoint(transform(all_tracks, other -> st_closestpoint(other, pt))))))\"))\\\n",
    "           .persist()\n",
    "\n",
    "route_filter = \"route_id = 'Isthmus Cv - Marina del Rey'\"\n",
    "\n",
    "map = EsriJSMap(basemap=\"oceans\", height=\"800px\")\n",
    "map.add_layer(mean_routes.where(route_filter).select(F.explode(\"all_tracks\")), color=\"gray\", width=1)\n",
    "map.add_layer(mean_routes.where(route_filter).select(\"rep_track\"), color=\"blue\")\n",
    "map.add_layer(mean_routes.where(route_filter).select(\"mean_trip_line\"), width=3, color=\"black\", style=\"dash\")\n",
    "map.display()\n",
    "\n",
    "if output_path:\n",
    "    mean_routes.drop(\"all_tracks\", \"mean_trip_line\")\\\n",
    "      .repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/representative_trips\")\n",
    "\n",
    "mean_routes = mean_routes.drop(\"all_tracks\", \"rep_track\")\n",
    "\n",
    "if output_path:\n",
    "    mean_routes.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/mean_routes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine how far each trip deviates from its common route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_deviation = trips.join(mean_routes, on=[\"route_id\"])\\\n",
    "  .withColumn(\"deviation\", ST.hausdorff_distance(\"track\", \"mean_trip_line\"))\\\n",
    "  .drop(\"rep_track\", \"mean_trip_line\")\n",
    "\n",
    "route_deviation.where(route_filter).st.plot(basemap=\"light\", figsize=demo_figsize, cmap_values=\"deviation\", legend=True)\n",
    "\n",
    "if output_path:\n",
    "    route_deviation.repartition(1).write.format(\"geoparquet\").mode(\"overwrite\").save(f\"{output_path}/route_deviations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
